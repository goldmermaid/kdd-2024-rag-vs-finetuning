{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4480da3",
   "metadata": {},
   "source": [
    "![image](../images/kdd24-logo-small.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ca6cfc0",
   "metadata": {},
   "source": [
    "### Hands-on Tutorial\n",
    "## Domain-Driven LLM Development: Insights into RAG and Fine-Tuning Practices\n",
    "### Lab 2.3 (optional) : LLM Fine-Tuning through DPO    \n",
    "#### Summary: \n",
    "This lab focused on fine-tuning with preference alignment - Direct Preference Optimization (DPO) on Meta-Llama-3-8B-Instruct SFT model   \n",
    "\n",
    "- The training dataset is from CUAD - BONTONSTORESINC_04_20_2018-EX-99.3-AGENCY AGREEMENT.PDF and evaluation metric on Meta-Llama-3-8B-Instruct SFT model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"trl<0.9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from operator import itemgetter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc00f0-905d-4a70-81a8-eccd304bc9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer,TrainingArguments\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b17ae-c267-4d60-95cc-d0fcd5f1c189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import DPOTrainer  \n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77637d51",
   "metadata": {},
   "source": [
    "### Construct training data\n",
    "\n",
    "In this step, we construct training dataset from the LLM responses and feedback score    \n",
    "\n",
    "[question, answer, feedback_score]   \n",
    "\n",
    "The feedback score can come from human evaluation or AI evaluation. For the Reinforcement Learning, we need to categorize the answers into \"chosen_answer\" and \"rejected_answer\", based on the feedback_score. For example, any answers with feedback_score greater than a threshold (such as 4 out of 5) are \"chosen\" otherwise \"rejected\". The processed data format is   \n",
    "\n",
    "[question, chosen_response, rejected_response] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "def construct_trining_data(df, threshold):\n",
    "    \n",
    "    df['tup'] = list(zip(df['response'], df['eval_score']))\n",
    "\n",
    "    #grouping together all the answers for a given question along with its feedback\n",
    "    df_g = df.groupby('prompt')['tup'].apply(list).reset_index()\n",
    "\n",
    "    # sort each group based on the feedback score\n",
    "    df_g[\"sorted_tup\"] = df_g[\"tup\"].apply(lambda x :sorted(x,key=itemgetter(1)) )\n",
    "\n",
    "    # answer with highest feedback score is \"chosen\"\n",
    "    df_g[\"chosen\"] = df_g[\"sorted_tup\"].apply(lambda x: x[-1][0])\n",
    "    df_g[\"chosen_score\"] = df_g[\"sorted_tup\"].apply(lambda x: x[-1][1])\n",
    "\n",
    "    # answer with highest feedback score is \"rejected\"\n",
    "    df_g[\"rejected\"] = df_g[\"sorted_tup\"].apply(lambda x: x[0][0])\n",
    "    df_g[\"rejected_score\"] = df_g[\"sorted_tup\"].apply(lambda x: x[0][1])\n",
    "    df_g = df_g.dropna()\n",
    "    \n",
    "    df_g = df_g[(df_g['chosen_score']>=threshold) & (df_g['rejected_score']<threshold)]\n",
    "    \n",
    "    # build dataset in [instruction, chosen_response, rejected_response]\n",
    "    rows = []\n",
    "    for record in df_g.itertuples(index=True, name='Pandas'):\n",
    "        if record is None or len(record) == 0:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"instruction\": record.prompt,\n",
    "            \"chosen_response\": record.chosen,\n",
    "            \"rejected_response\": record.rejected\n",
    "        })\n",
    "        \n",
    "    processed_dataset = Dataset.from_list(rows)\n",
    "    processed_df = processed_dataset.to_pandas()\n",
    "    \n",
    "    return processed_df, processed_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e8af5",
   "metadata": {},
   "source": [
    "Load the SFT data file generated in the Lab 2.2 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFT_FILE =  '../lab-data/sft_trn_result.csv'\n",
    "\n",
    "df = pd.read_csv(SFT_FILE)\n",
    "df = df.drop(['token_overlap_recall','rouge_l_recall'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['prompt','reference','response','eval_score']  # rename the columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5919b44",
   "metadata": {},
   "source": [
    "Set the threshold to categorize chosen and rejected responses, then generate the training dataset/dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4229431",
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold = 0.6\n",
    "prepared_df, prepared_dataset = construct_trining_data(df, Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03907ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd217ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you like, you can store the training data in a csv file \n",
    "OUTPUT_FILE = '../lab-data/dpo_trn_data.csv' \n",
    "prepared_df.to_csv(OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ad58f9",
   "metadata": {},
   "source": [
    "### Load the SFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e716dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5611ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./ft_model_llama3-8b_instruct_cuad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2353df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize static strings for the prompt template\n",
    "INTRO_BLURB = 'Below is an instruction that describes a task. Write a response that appropriately completes the request. \\n'\n",
    "\n",
    "INSTRUCTION_KEY = \"\"\"\n",
    "[Instruction]: You are a legal AI assistant reviwing commercial contracts. \n",
    "Please provide answer to the question listed below about the important contract clauses. \n",
    "The questions are provided after the [Question] tag, present your answer after the [Response] tag. \n",
    "DO NOT put any premables in the response. If you don't know the answer, just say I don't know, DO NOT make up the answers' \n",
    "\"\"\"\n",
    "\n",
    "INPUT_KEY = '[Question]: '\n",
    "RESPONSE_KEY = '[Response]: '\n",
    "END_KEY = \"[End]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921c581",
   "metadata": {},
   "source": [
    "Load FM and Peft-load adapter then merge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6047456",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_in_4bit = True\n",
    "bnb_4bit_use_double_quant = True\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "bnb_4bit_compute_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = load_in_4bit,\n",
    "        bnb_4bit_use_double_quant = bnb_4bit_use_double_quant,\n",
    "        bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
    "        bnb_4bit_compute_dtype = bnb_4bit_compute_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69133618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "model_ft = AutoModelForCausalLM.from_pretrained(  \n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d13ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = PeftModel.from_pretrained(\n",
    "    model_ft, \n",
    "    output_dir, \n",
    "    torch_dtype = torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d016c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model_ft.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a5c49",
   "metadata": {},
   "source": [
    "Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ft = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer_ft.pad_token = tokenizer_ft.eos_token\n",
    "tokenizer_ft.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c17c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681a98d",
   "metadata": {},
   "source": [
    "### Prepare the DPO training data in Datasets format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5305ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prompt_and_responses(samples):\n",
    "    return {\n",
    "        \"prompt\": samples[\"instruction\"],\n",
    "        \"chosen\": samples[\"chosen_response\"],\n",
    "        \"rejected\": samples[\"rejected_response\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=OUTPUT_FILE, split=\"train\")\n",
    "\n",
    "original_columns = dataset.column_names\n",
    "\n",
    "dataset = dataset.map(\n",
    "    return_prompt_and_responses,\n",
    "    batched=True,\n",
    "    remove_columns=original_columns\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac587a8-0e07-4609-a776-652d2a4d98c3",
   "metadata": {},
   "source": [
    "### Setup PEFT/LoRA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4175432",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"./dpo_model_llama3-8b_instruct_cuad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  \n",
    "    lora_alpha=32,  \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020e39e",
   "metadata": {},
   "source": [
    "Setup DPO parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=2,    \n",
    "    save_steps= 10000,\n",
    "    learning_rate=1e-6,    \n",
    "    logging_steps=10,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    remove_unused_columns=False    # for using DPODataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e582aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model_ft,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer_ft,\n",
    "    peft_config=lora_config,\n",
    "    max_prompt_length=1024,\n",
    "    max_length=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9caca3",
   "metadata": {},
   "source": [
    "### Launch training and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ac0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e31070",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.save_model(OUTPUT_DIR)\n",
    "\n",
    "dpo_trainer.model.save_pretrained(OUTPUT_DIR)   \n",
    "tokenizer_ft.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f80e8",
   "metadata": {},
   "source": [
    "### Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6affc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09767c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def Llama_Infer(prompt):\n",
    "\n",
    "    st = time.time()\n",
    "    \n",
    "    batch = tokenizer_ft(prompt, return_tensors=\"pt\")\n",
    "    input_ids = batch[\"input_ids\"].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        output = model_ft.generate(input_ids, \n",
    "                                    max_new_tokens=256,\n",
    "                                    do_sample=True,\n",
    "                                    temperature = 0.01,\n",
    "                                    pad_token_id=tokenizer_ft.eos_token_id,\n",
    "                                    )[0]       \n",
    "\n",
    "        response = tokenizer_ft.decode(output)\n",
    "\n",
    "\n",
    "\n",
    "    et = time.time()\n",
    "    elapsed_time = et - st\n",
    "    \n",
    "    #print(\"generated_text = \", response)\n",
    "    if('[Response]:' in response):\n",
    "        full_text = response.split('[Response]:')[1].strip()\n",
    "        if ('[End]' in response):\n",
    "            full_text = full_text.split('[End]')[0].strip()\n",
    "    else:\n",
    "        full_text = response\n",
    "    answer = full_text\n",
    "    \n",
    "    return answer, elapsed_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_FILE = '../lab-data/ENERGOUSCORP_qa.csv'\n",
    "df_test_data = pd.read_csv(TRN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 1\n",
    "\n",
    "query = df_test_data['question'][IDX]\n",
    "gt = df_test_data['answer'][IDX]\n",
    "\n",
    "blurb = f\"{INTRO_BLURB}\"\n",
    "instruction = f\"{INSTRUCTION_KEY}\"\n",
    "input_context = f'{INPUT_KEY}{query}\\n\\n{RESPONSE_KEY}'\n",
    "\n",
    "prompt = blurb+'\\n'+instruction+'\\n'+input_context\n",
    "\n",
    "answer, elapse_time = Llama_Infer(prompt)\n",
    "print(\"Question = \", query, \"\\nAnswer = \", answer, \"\\nGT = \", gt, \"\\nElapse time = \", elapse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb8880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
