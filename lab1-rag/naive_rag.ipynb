{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920bfb1-54a7-4c8c-9c45-591759e73b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be99b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8173e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text using PyMuPDF\n",
    "def extract_text_from_pdf_mupdf(pdf_path):\n",
    "    text = \"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text from the PDF using PyMuPDF\n",
    "pdf_text_mupdf = extract_text_from_pdf_mupdf(\"../lab-data/BONTONSTORESINC_04_20_2018-EX-99.3-AGENCY AGREEMENT.PDF\")\n",
    "pdf_text_mupdf[:2000]  # Displaying the first 2000 characters to get an overview of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size, overlap):\n",
    "    \"\"\"\n",
    "    Chunk text into smaller segments with a specified chunk size and overlap.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to be chunked.\n",
    "    - chunk_size (int): The size of each chunk.\n",
    "    - overlap (int): The number of characters that overlap between chunks.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    if chunk_size <= overlap:\n",
    "        raise ValueError(\"Chunk size must be greater than overlap\")\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "\n",
    "    while start < len(text):\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "        end = start + chunk_size\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(pdf_text_mupdf, 1024, 256)\n",
    "print(len(chunks))\n",
    "chunks[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62329911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bedrock client\n",
    "client = boto3.client('bedrock-runtime', region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed text\n",
    "def embed_text(input_text):\n",
    "    # Create the request payload\n",
    "    payload = {\n",
    "        \"inputText\": input_text,\n",
    "        \"dimensions\": 512,  # Specify the desired dimension size\n",
    "        \"normalize\": True  # Whether to normalize the output embeddings\n",
    "    }\n",
    "\n",
    "    # Invoke the model\n",
    "    response = client.invoke_model(\n",
    "        body=json.dumps(payload),\n",
    "        modelId='amazon.titan-embed-text-v2:0',  # Specify the Titan embedding model\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    # Get the embedding result\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    embedding = response_body.get('embedding')\n",
    "    return embedding\n",
    "\n",
    "# Print the embedding\n",
    "print(embed_text(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cafe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyepsilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh ../setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyepsilla import vectordb\n",
    "## connect to vectordb\n",
    "db = vectordb.Client(\n",
    "  host='localhost',\n",
    "  port='8888'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.unload_db(\"kdd_lab1_rag\")\n",
    "db.load_db(db_name=\"kdd_lab1_rag\", db_path=\"/tmp/kdd_lab1_rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7eb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.use_db(db_name=\"kdd_lab1_rag\")\n",
    "db.create_table(\n",
    "  table_name=\"NaiveRAG\",\n",
    "  table_fields=[\n",
    "    {\"name\": \"ID\", \"dataType\": \"INT\", \"primaryKey\": True},\n",
    "    {\"name\": \"Doc\", \"dataType\": \"STRING\"},\n",
    "    {\"name\": \"Embedding\", \"dataType\": \"VECTOR_FLOAT\", \"dimensions\": 512}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbc7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records = [\n",
    "    {\n",
    "        \"ID\": index,\n",
    "        \"Doc\": text,\n",
    "        \"Embedding\": embed_text(text)\n",
    "    }\n",
    "    for index, text in enumerate(chunks)\n",
    "]\n",
    "records[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a90d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert(\"NaiveRAG\", records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "    # Create the request payload\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": 0,  # Adjust the randomness of the output\n",
    "        \"max_gen_len\": 128\n",
    "    }\n",
    "\n",
    "    # Initialize the Bedrock runtime client\n",
    "    client = boto3.client('bedrock-runtime', region_name='us-west-2')\n",
    "\n",
    "    # Invoke the model\n",
    "    response = client.invoke_model(\n",
    "        modelId='meta.llama3-8b-instruct-v1:0',\n",
    "        contentType='application/json',\n",
    "        accept='application/json',\n",
    "        body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    byte_response = response['body'].read()\n",
    "    json_string = byte_response.decode('utf-8')\n",
    "\n",
    "    # Get the chat response\n",
    "    response_body = json.loads(json_string)\n",
    "    chat_response = response_body.get('generation')\n",
    "\n",
    "    return chat_response\n",
    "\n",
    "# Example usage\n",
    "input_text = \"How are you?\"\n",
    "prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "{input_text}[/INST]\n",
    "\"\"\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90733e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_retriever(question, top_k):\n",
    "    code, resp = db.query(\n",
    "        table_name=\"NaiveRAG\",\n",
    "        query_field=\"Embedding\",\n",
    "        query_vector=embed_text(question),\n",
    "        limit=top_k\n",
    "    )\n",
    "    return resp[\"result\"]\n",
    "basic_retriever(\"What's the agreement date?\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_rag(question):\n",
    "    docs = basic_retriever(question, 5)\n",
    "    docs_str = \"------------------------\\n\"\n",
    "    for doc in docs:\n",
    "        docs_str += doc[\"Doc\"] + \"------------------------\\n\"\n",
    "    prompt = f\"\"\"\n",
    "<s>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "\n",
    "Your answer should be grounded by the information provided in the documents below.\n",
    "Don't make up answers.\n",
    "Don't explain your thought process.\n",
    "Directly answer the question in concise way.\n",
    "\n",
    "<documents>\n",
    "{docs_str}\n",
    "</documents>\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "    return generate(prompt)\n",
    "\n",
    "naive_rag(\"What's the agreement date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8e9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
